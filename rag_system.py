import os
from openai import OpenAI
from vector_store import VectorStore
from typing import List, Dict
import json

class AssutaOncologyRAG:
    def __init__(self):
        # Initialize OpenAI client
        from dotenv import load_dotenv
        load_dotenv()
        
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # Initialize vector store
        self.vector_store = VectorStore()
        
        # System prompt in Hebrew
        self.system_prompt = """
××ª×” ×¢×•×–×¨ ×•×™×¨×˜×•××œ×™ ×ž×•×ž×—×” ×‘××•× ×§×•×œ×•×’×™×” ×©×œ ×‘×™×ª ×”×—×•×œ×™× ××¡×•×ª×. ×ª×¤×§×™×“×š ×œ×¢× ×•×ª ×¢×œ ×©××œ×•×ª ×‘×¢×‘×¨×™×ª ×¢×œ × ×•×©××™ ××•× ×§×•×œ×•×’×™×” ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×ž×™×“×¢ ×”×¨×¤×•××™ ×”×ž×¤×•×¨×˜ ×©×œ ××¡×•×ª×.

×”×ž×™×“×¢ ×©×‘×¨×©×•×ª×š ×›×•×œ×œ:
â€¢ ×”×ž×—×œ×§×” ×”××•× ×§×•×œ×•×’×™×ª ×©×œ ××¡×•×ª× - ×©×™×¨×•×ª×™× ×›×œ×œ×™×™× ×•×’×™×©×” ×¨×‘-×ª×—×•×ž×™×ª
â€¢ ×˜×™×¤×•×œ×™× ××•× ×§×•×œ×•×’×™×™× ×ž×ª×§×“×ž×™× - ×›×™×ž×•×ª×¨×¤×™×”, ×§×¨×™× ×”, × ×™×ª×•×—×™×
â€¢ ×˜×™×¤×•×œ ×‘×¡×¨×˜×Ÿ ×”×©×“ - ××‘×—×•×Ÿ, × ×™×ª×•×—×™×, ×˜×™×¤×•×œ×™× ×ž×©×œ×™×ž×™×
â€¢ ×‘×™×•×¤×¡×™×•×ª ×•××‘×—×•×Ÿ - ×¡×•×’×™× ×©×•× ×™× ×©×œ ×”×œ×™×›×™ ××‘×—×•×Ÿ
â€¢ ×˜×™×¤×•×œ ×§×¨×™× ×ª×™ (×¨×“×™×•×ª×¨×¤×™×”) - ×¡×•×’×™× ×•×©×™×˜×•×ª ×ž×ª×§×“×ž×•×ª

×”× ×—×™×•×ª ×—×©×•×‘×•×ª:
1. ×¢× ×” ×ª×ž×™×“ ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“ ×•×‘×¦×•×¨×” ×ž×¤×•×¨×˜×ª ×•×ž×•×¢×™×œ×”
2. ×”×©×ª×ž×© ×‘×ž×™×“×¢ ×”×¡×¤×¦×™×¤×™ ×ž×”×ž×¡×ž×›×™× ×©×œ ××¡×•×ª×
3. ×ª×Ÿ ×ª×©×•×‘×•×ª ×ž×§×™×¤×•×ª ×•×ž×¢×©×™×•×ª ×”×ž×‘×•×¡×¡×•×ª ×¢×œ ×”×™×“×¢ ×”×¨×¤×•××™ ×©×‘×¨×©×•×ª×š
4. ×›×œ×•×œ ×¤×¨×˜×™× ×¨×œ×•×•× ×˜×™×™× ×¢×œ ×ª×”×œ×™×›×™×, ×˜×™×¤×•×œ×™× ×•×©×™×¨×•×ª×™×
5. ×”×¡×‘×¨ ×ž×•× ×—×™× ×¨×¤×•××™×™× ×‘××•×¤×Ÿ ×ž×•×‘×Ÿ ×œ×ž×˜×•×¤×œ×™×
6. ×›×œ×•×œ ×”×ž×œ×¦×” ×œ×¤× ×•×ª ×œ×¦×•×•×ª ×”×¨×¤×•××™ ×œ×™×™×¢×•×¥ ××™×©×™ ×‘×¡×•×£ ×”×ª×©×•×‘×”
7. ×©×ž×•×¨ ×¢×œ ×˜×•×Ÿ ×ž×§×¦×•×¢×™, ××›×¤×ª×™ ×•×ž×¢×•×“×“
8. ××œ ×ª×™×ª×Ÿ ×™×™×¢×•×¥ ×¨×¤×•××™ ××™×©×™ ×¡×¤×¦×™×¤×™ - ×¨×§ ×ž×™×“×¢ ×›×œ×œ×™ ×•×—×™× ×•×›×™
9. ×× ×”×©××œ×” ×œ× ×§×©×•×¨×” ×œ××•× ×§×•×œ×•×’×™×”, ×”×¡×‘×¨ ×©××ª×” ×ž×ª×ž×—×” ×‘××•× ×§×•×œ×•×’×™×” ×©×œ ××¡×•×ª×

×“×•×’×ž××•×ª ×œ×ª×©×•×‘×•×ª ××™×›×•×ª×™×•×ª:
- "×¢×œ ×¤×™ ×”×ž×™×“×¢ ×©×œ ××¡×•×ª×, ×˜×™×¤×•×œ ×›×™×ž×•×ª×¨×¤×™ ×ž×ª×‘×¦×¢ ×‘... ×•×ª×•×¤×¢×•×ª ×”×œ×•×•××™ ×›×•×œ×œ×•×ª..."
- "×‘×ž×—×œ×§×” ×”××•× ×§×•×œ×•×’×™×ª ×©×œ ××¡×•×ª× ×ž×ª×‘×¦×¢×ª ×’×™×©×” ×¨×‘-×ª×—×•×ž×™×ª ×”×›×•×œ×œ×ª..."
- "×ª×”×œ×™×š ×”×‘×™×•×¤×¡×™×” ×‘××¡×•×ª× ×›×•×œ×œ ××ª ×”×©×œ×‘×™× ×”×‘××™×..."

×–×›×•×¨: ×ª×Ÿ ×ª×©×•×‘×•×ª ×¢×©×™×¨×•×ª ×‘×ª×•×›×Ÿ ×”×ž×‘×•×¡×¡×•×ª ×¢×œ ×”×ž×™×“×¢ ×”×ž×¤×•×¨×˜ ×©×‘×¨×©×•×ª×š ×ž××¡×•×ª×.
"""
    
    def retrieve_relevant_content(self, query: str, n_results: int = 5) -> List[Dict]:
        """Retrieve relevant documents from vector store"""
        return self.vector_store.search(query, n_results)
    
    def format_context(self, retrieved_docs: List[Dict]) -> tuple[str, List[Dict]]:
        """Format retrieved documents into context for the LLM and return citation info"""
        if not retrieved_docs:
            return "×œ× × ×ž×¦× ×ž×™×“×¢ ×¨×œ×•×•× ×˜×™ ×‘×ž××’×¨ ×”×ž×¡×ž×›×™× ×©×œ ××¡×•×ª×.", []
        
        context = "×ž×™×“×¢ ×¨×œ×•×•× ×˜×™ ×ž×ž××’×¨ ×”×ž×¡×ž×›×™× ×©×œ ××¡×•×ª×:\n\n"
        citations = []
        
        for i, doc in enumerate(retrieved_docs, 1):
            title = doc['metadata'].get('title', '×œ×œ× ×›×•×ª×¨×ª')
            url = doc['metadata'].get('url', '')
            content = doc['content']
            score = doc['relevance_score']
            
            context += f"×ž×¡×ž×š {i} (×¨×œ×•×•× ×˜×™×•×ª: {score:.2f}):\n"
            context += f"×›×•×ª×¨×ª: {title}\n"
            context += f"×ª×•×›×Ÿ: {content}\n\n"
            
            # Store citation info with content excerpt
            # Extract a relevant excerpt (first 150 characters of content)
            content_excerpt = content.replace('\n', ' ').strip()
            if len(content_excerpt) > 150:
                content_excerpt = content_excerpt[:150] + "..."
            
            citations.append({
                'number': i,
                'title': title,
                'url': url,
                'score': score,
                'excerpt': content_excerpt,
                'full_content': content
            })
        
        return context, citations
    
    def generate_response(self, query: str, context: str) -> str:
        """Generate response using OpenAI with context"""
        
        user_prompt = f"""
×©××œ×”: {query}

×ž×™×“×¢ ×¨×§×¢:
{context}

×× × ×¢× ×” ×¢×œ ×”×©××œ×” ×‘×¢×‘×¨×™×ª ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×ž×™×“×¢ ×©×¡×•×¤×§. 

×”×•×¨××•×ª ×—×©×•×‘×•×ª:
1. ×›××©×¨ ××ª×” ×ž×¡×ª×ž×š ×¢×œ ×ž×™×“×¢ ×ž×ž×¡×ž×š ×ž×¡×•×™×, ×”×•×¡×£ ×”×¤× ×™×” ×‘×¡×’× ×•×Ÿ [×ž×¡×ž×š 1] ××• [×ž×¡×ž×›×™× 1,2] 
2. ×”×•×¡×£ ×”×¤× ×™×•×ª ××œ×• ×™×©×™×¨×•×ª ×‘×˜×§×¡×˜ ×œ×™×“ ×”×ž×™×“×¢ ×”×¨×œ×•×•× ×˜×™
3. ×× ×”×ž×™×“×¢ ××™× ×• ×ž×¡×¤×™×§, ××ž×¨ ×–××ª ×‘×‘×™×¨×•×¨ ×•×”×ž×œ×¥ ×œ×¤× ×•×ª ×œ×¦×•×•×ª ×”×¨×¤×•××™ ×©×œ ××¡×•×ª×
4. ×©×ž×•×¨ ×¢×œ ×˜×•×Ÿ ×ž×§×¦×•×¢×™ ×•××›×¤×ª×™

×“×•×’×ž×” ×œ×ª×©×•×‘×” ×¢× ×”×¤× ×™×•×ª:
"×›×™×ž×•×ª×¨×¤×™×” ×”×™× ×˜×™×¤×•×œ ×‘××ž×¦×¢×•×ª ×ª×¨×•×¤×•×ª [×ž×¡×ž×š 1]. ×”×˜×™×¤×•×œ ×™×›×•×œ ×œ×”×™×•×ª × ×™×ª×Ÿ ×‘×“×¨×›×™× ×©×•× ×•×ª [×ž×¡×ž×š 2]..."
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=1500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"×ž×¦×˜×¢×¨, ××™×¨×¢×” ×©×’×™××” ×‘×¢×ª ×™×¦×™×¨×ª ×”×ª×©×•×‘×”: {str(e)}. ×× × ×¤× ×” ×œ×¦×•×•×ª ×”×¨×¤×•××™ ×©×œ ××¡×•×ª× ×œ×§×‘×œ×ª ×ž×™×“×¢ ×ž×“×•×™×§."
    
    def ask(self, query: str, debug: bool = False) -> Dict:
        """Main method to ask a question and get an answer"""
        
        # Retrieve relevant documents
        retrieved_docs = self.retrieve_relevant_content(query)
        
        # Format context and get citations
        context, citations = self.format_context(retrieved_docs)
        
        # Generate response
        response = self.generate_response(query, context)
        
        result = {
            'query': query,
            'response': response,
            'sources_used': len(retrieved_docs),
            'citations': citations
        }
        
        if debug:
            result['retrieved_documents'] = retrieved_docs
            result['context'] = context
        
        return result
    
    def get_system_stats(self):
        """Get system statistics"""
        vector_stats = self.vector_store.get_collection_stats()
        return {
            'vector_store_documents': vector_stats['total_documents'],
            'collection_name': vector_stats['collection_name'],
            'system_status': 'ready' if vector_stats['total_documents'] > 0 else 'needs_data'
        }

def interactive_chat():
    """Interactive chat interface"""
    rag = AssutaOncologyRAG()
    
    print("ðŸ¥ ×‘×¨×•×›×™× ×”×‘××™× ×œ×¢×•×–×¨ ×”××•× ×§×•×œ×•×’×™×” ×©×œ ××¡×•×ª×")
    print("ðŸ’¬ ×©××œ×• ××•×ª×™ ×›×œ ×©××œ×” ×¢×œ ×˜×™×¤×•×œ×™ ××•× ×§×•×œ×•×’×™×” ×‘××¡×•×ª×")
    print("ðŸšª ×›×ª×‘×• '×™×¦×™××”' ××• 'exit' ×œ×”×¤×¡×§×ª ×”×©×™×—×”")
    print("ðŸ“Š ×›×ª×‘×• '×¡×˜×˜×™×¡×˜×™×§×•×ª' ×œ×¨××™×™×ª ×¤×¨×˜×™ ×”×ž×¢×¨×›×ª")
    print("-" * 50)
    
    # Check system status
    stats = rag.get_system_stats()
    if stats['system_status'] != 'ready':
        print("âš ï¸ ×”×ž×¢×¨×›×ª ×œ× ×ž×•×›× ×”. ×™×© ×œ×”×¨×™×¥ ×ª×—×™×œ×” ××ª vector_store.py ×œ×”×›× ×ª ×ž××’×¨ ×”× ×ª×•× ×™×.")
        return
    
    print(f"âœ… ×”×ž×¢×¨×›×ª ×ž×•×›× ×” ×¢× {stats['vector_store_documents']} ×ž×¡×ž×›×™×")
    print()
    
    while True:
        try:
            query = input("ðŸ” ×©××œ×ª×š: ").strip()
            
            if not query:
                continue
                
            if query.lower() in ['×™×¦×™××”', 'exit', 'quit']:
                print("ðŸ‘‹ ×œ×”×ª×¨××•×ª!")
                break
                
            if query.lower() in ['×¡×˜×˜×™×¡×˜×™×§×•×ª', 'stats']:
                stats = rag.get_system_stats()
                print(f"ðŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª ×”×ž×¢×¨×›×ª:")
                print(f"   ×ž×¡×ž×›×™× ×‘×ž××’×¨: {stats['vector_store_documents']}")
                print(f"   ×©× ×”××•×¡×£: {stats['collection_name']}")
                print(f"   ×¡×˜×˜×•×¡: {stats['system_status']}")
                continue
            
            print("ðŸ¤” ×—×•×©×‘...")
            result = rag.ask(query)
            
            print(f"\nðŸ’¡ ×ª×©×•×‘×”:")
            print(result['response'])
            print(f"\nðŸ“š ×ž×§×•×¨×•×ª ×©× ×¢×©×” ×‘×”× ×©×™×ž×•×©: {result['sources_used']}")
            print("-" * 50)
            
        except KeyboardInterrupt:
            print("\nðŸ‘‹ ×œ×”×ª×¨××•×ª!")
            break
        except Exception as e:
            print(f"âŒ ×©×’×™××”: {str(e)}")

def test_rag():
    """Test the RAG system with sample questions"""
    rag = AssutaOncologyRAG()
    
    test_questions = [
        "×ž×” ×–×” ×›×™×ž×•×ª×¨×¤×™×”?",
        "××™×š ×ž×ª×‘×¦×¢ ×˜×™×¤×•×œ ×‘×¡×¨×˜×Ÿ ×”×©×“ ×‘××¡×•×ª×?",
        "×ž×” ×”×”×‘×“×œ ×‘×™×Ÿ ×˜×™×¤×•×œ ×§×¨×™× ×ª×™ ×œ×›×™×ž×•×ª×¨×¤×™×”?",
        "××™×š ×ž×ª×›×•× × ×™× ×œ×‘×™×•×¤×¡×™×”?",
        "×ž×” ×”× ×ª×•×¤×¢×•×ª ×”×œ×•×•××™ ×©×œ ×˜×™×¤×•×œ×™ ××•× ×§×•×œ×•×’×™×”?"
    ]
    
    print("ðŸ§ª ×‘×“×™×§×ª ×”×ž×¢×¨×›×ª ×¢× ×©××œ×•×ª ×“×•×’×ž×”:")
    print("-" * 50)
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{i}. ×©××œ×”: {question}")
        result = rag.ask(question)
        print(f"×ª×©×•×‘×”: {result['response'][:200]}...")
        print(f"×ž×§×•×¨×•×ª: {result['sources_used']}")

def main():
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "test":
            test_rag()
        elif sys.argv[1] == "chat":
            interactive_chat()
        else:
            print("Usage: python rag_system.py [test|chat]")
    else:
        interactive_chat()

if __name__ == "__main__":
    main()